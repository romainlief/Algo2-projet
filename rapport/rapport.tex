\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[a4paper,left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{indentfirst}
\usepackage{appendix}
\usepackage{libertine}
\usepackage{titlesec}
\usepackage{eso-pic}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{caption}
\usepackage{color}
\usepackage{setspace}
\usepackage[T1]{fontenc}
\usepackage[hyphens]{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex}
\addbibresource{source.bib}\usepackage[linkbordercolor=white]{hyperref}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{enumitem}
\usepackage{siunitx}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{commath}
\usepackage{cancel}
\usepackage{pdflscape}
\usepackage{svg}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e} % Retain only one package
\usepackage{comment}
\usepackage{placeins}

\usepackage{listings}
\lstset{literate=%
    {à}{{\`a}}1 {â}{{\^a}}1 {é}{{\'e}}1 {è}{{\`e}}1 {ê}{{\^e}}1 {ë}{{\"e}}1 {î}{{\^i}}1 {ï}{{\"i}}1 {ô}{{\^o}}1 {ö}{{\"o}}1 {ù}{{\`u}}1 {û}{{\^u}}1 {ü}{{\"u}}1 {ç}{{\c{c}}}1 {Ç}{{\c{C}}}1{―}{{\textemdash}}1
    {’}{{'}}1 {‘}{{`}}1 {“}{{``}}1 {”}{{''}}1
}
\urlstyle{same}
\pagestyle{fancy}
\fancyhead[L]{\leftmark}
\fancyhead[R]{}
\renewcommand{\subsectionmark}[1]{}


\usepackage{titlesec}
\usepackage{hyperref}

\titleclass{\subsubsubsection}{straight}[\subsection]


\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % optional; useful if paragraphs are to be numbered


\titleformat{\subsubsubsection}
  {\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
  {3.25ex \@plus1ex \@minus.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
  {3.25ex \@plus1ex \@minus .2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
\def\toclevel@paragraph{6}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}
\def\l@paragraph{\@dottedtocline{5}{10em}{5em}}
\def\l@subparagraph{\@dottedtocline{6}{14em}{6em}}
\makeatother
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\setlength{\headheight}{14.5pt}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{0.6}
\renewcommand{\headrulewidth}{1pt}
\newcommand{\HRule}{\rule{\linewidth}{0.3mm}}
\newcommand\BackgroundPic{%
	\put(0,0){%
		\parbox[b][\paperheight]{\paperwidth}{%
			\vfill
			\centering
			\includegraphics[width=\paperwidth,height=\paperheight,%
			keepaspectratio]{background.png}%
			\vfill}}}

% -----------------------------------------------------


\begin{document}
\AddToShipoutPicture*{\BackgroundPic}
\begin{titlepage}
  \begin{sffamily}
  \begin{flushleft} \large
    \includegraphics[height=2.0cm]{logo_ulb.jpg}
    \vspace{5cm}
   \end{flushleft}
  \begin{center}

    %Title
	\textsc{\huge INFO-F203 - Projets d'algorithmique 2}\\[1cm]

    \HRule \\[0.7cm]

	\textsc {\Huge Projet Mobilité}\\[0.4cm]

    \HRule \\[1.2cm]

% Author and supervisor
\begin{minipage}{0.5\textwidth}
\begin{flushleft} \large
\emph{Auteurs:}\\
Romain \textsc{Liefferinckx} - 000591790\\
Manuel \textsc{Rocca} - 000596086\\


\end{flushleft}
\end{minipage}


\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Professeurs:} \\
Jean  \textsc{Cardinal}\\
\emph{Assistants:} \\
Robin \textsc{Petit}
\end{flushright}
\end{minipage}


    \vfill

    %Bottom of the page
    {\large Année académique 2024-2025}
  \end{center}

  \end{sffamily}
\end{titlepage}


\clearpage


\tableofcontents

\newpage

% -----------------------------------------------------

\section{Introduction}
Dans le cadre de notre cours d'algorithmique INFO F-203, l'occasion s'est présentée à nous de créer un programme cherchant un chemin optimal
entre un point A et un point B sur base d'une heure de départ. En effet, sur base d'un ensemble de données
fournies sous format \emph{General Transit Feed Specification} (\textbf{GTFS}), nous avons utilisé le \emph{Connexion Scan Algorithm} (\textbf{CSA})
pour implémenter notre chercheur de chemin en \emph{Java}. 

Dans les sections à suivre, nous abordons l'initialisation des données, des structures formées à partir de celles-ci pour notre
implémentation et certains détails techniques comme la complexité temporelle et spatiale. Nous justifierons également certains choix
comme celui de l'algorithme précisé ci-dessus, à savoir le \textbf{CSA}.


\section{Initialisation des données}
Dans cette section nous expliquons les procédés utilisés pour charger les données en mémoire à partir des fichiers CSV fournis ainsi que
les structures de données utilisées pour leur stockage et leur utilisation optimale dans l'algorithme choisi par nos soins.

Tout d'abord, décrivons brièvement la classe Parser, qui se charge de la lecture des fichiers CSV et de la création de dictionnaires (\emph{HashMap}) contenant les données chargées, faciles d'accès.
Nous avons créé, pour chaque type de fichier CSV, une classe de stockage qui contient les attributs correspondants aux champs du fichier CSV. Quelques subtilités notables au sujet de ces classes sont
décrites dans les sections suivantes.

\subsection{Objets de base pour le stockage}
Les fichiers CSV fournis contiennent des informations sur les arrêts, les trajets, les horaires et les routes de quatre entreprises de transport en commun,
à savoir la STIB en région Bruxelloise, TEC en région Wallone, DELIJN en région FLamande et, finalement, la SNCB pour le transport ferroviaire au niveau national.

Pour chaque type de fichier CSV, voici donc les classes correspondantes créées pour contenir les données de manière accessible.

\subsubsection{La classe Route}
Cette classe est une simple classe de stockage, chaque attribut correspondant à un champ des fichiers \emph{routes.csv}.

% Table qui détaille la classe Route
\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\
    \hline
    route\_id & final String & L'identifiant de la route représentée \\
    route\_short\_name & final String & Le nom de la route raccourci \\
    route\_long\_name & final String & Le nom de la route complet \\
    route\_type & final String & Le type de véhicule utilisant cette route \\
    \hline
    \end{tabular}
    \caption{Classe Route}
\end{table}

\subsubsection{La classe StopTime}
La particularité de cette classe est qu'il lui manque le champ trip\_id donné dans les CSV concernés. Ce choix découle
de la structure de la classe Trip détaillée dans la section \hyperref[sec:trip]{2.1.4}.
% Table qui détaille la classe StopTime
\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\
    \hline
    departure\_time & final String & L'heure du départ à partir de
                                   l'arrêt associé sur le trajet associé en format 
                                   heure;minutes;secondes \\
    stop\_id & final String & L'identifiant de l'arrêt associé \\
    stop\_sequence & final int & Le numéro de l'arrêt dans le trajet associé \\
    \hline
    \end{tabular}
    \caption{Classe StopTime}
\end{table}

\subsubsection{La classe Stop}
Dans cette classe, hormis le fait que chaque champ des fichiers \emph{routes.csv} est repris, nous avons fait le choix d'ajouter
une liste de trip\_id, permettant de retrouver efficacement chaque trajet partant de cet arrêt ainsi qu'une liste de \hyperref[sec:walk]{\emph{Walk}}, permettant
d'avoir un accès rapide à tous les arrêts accessibles à pied depuis cet arrêt.

Cette classe comprend également une méthode \emph{getDistanceToOther} qui permet de calculer la distance entre deux arrêts en utilisant la formule de Haversine,
implémentée dans une classe annexe, la classe \emph{Calculator}.

% Table qui détaille la classe Stop
\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\
    \hline
    stop\_id & final String & L'identifiant du stop représenté \\
    stop\_name & final String & Le nom du stop \\
    stop\_lat & final String & La latitude du stop \\
    stop\_lon & final String & La longitude du stop \\
    trip\_ids & List$<$String$>$ & La liste des tous les trips (leurs identifiants) partant de ce stop \\
    walks & List$<$Walk$>$ & La liste de tous les arrêts accessibles à pied depuis ce stop \\
    \hline
    \end{tabular}
    \caption{Classe Stop}
\end{table}

\subsubsection{La classe Trip}
\label{sec:trip}
Une fois de plus, en plus des champs trouvés dans les fichiers \emph{trips.csv} retranscrits en attribut, nous avons ajouté
une liste d'heures d'arrêt associés à ce trajet. Ceci nous permet de construire efficacement les connexions entre arrêts affublées
de temps de départ et d'arrivée.

% Table qui détaille la classe Trip
\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\
    \hline
    trip\_id & final String & L'identifiant du trip représenté \\
    route\_id & final String & L'identifiant de la route sur laquelle il passe \\
    stop\_times & List$<$StopTime$>$ &  La liste de tous les StopTime associés à ce trip \\
    \hline
    \end{tabular}
    \caption{Classe Trip}
\end{table}

\subsection{Création des structures de données}
Une fois les données lues et contenues dans des dictionnaires faciles d'accès (accès en temps constant), nous procédons à la création de structures de données
pertinentes à notre algorithme de recherche de chemin, le CSA à l'aide de la classe Builder.

La classe Builder est responsable de la création d'une liste de connexions entre arrêts, de la création du BallTree utilisé pour construire efficacement les transferts à pied entre arrêts
et, finalement, la création de ces transferts à pied.

\subsubsection{La classe Connexion}
L'algorithme CSA se base, comme son nom l'indique, sur des connexions entre les différents arrêts. Pour traiter cet aspect, nous avons fait le choix logique
d'implémenter une classe \emph{Connexion}.

\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\
    \hline
    trip\_id & final String & L'identifiant du trajet utilisé par la connexion \\
    from\_id & final String & L'identifiant de l'arrêt de de départ \\
    to\_id & final String &  L'identifiant de l'arrêt d'arrivée \\
    departure\_time & final int & L'heure de départ de l'arrêt \emph{from\_id} \\
    arrival\_time & final int & L'heure d'arrivée à l'arrêt \emph{to\_id} \\
    \hline
    \end{tabular}
    \caption{Classe Trip}
\end{table}


\subsubsection{La class BallTree}
Afin de construire les transferts à pied (limités à une distance arbitraire), nous avons d'abord commencé par une implémentation brute-force en itérant, pour chaque arrêt, sur tous les
autres arrêts en $O(n^2)$, $n$ étant le nombre d'arrêts. Cependant, avec un total d'environ 65 000 arrêts, cette approche impliquait environ 4,5 milliards d'itérations avec, à chaque 
itération, une série d'opérations comme par exemple le calcul de la distance entre deux arrêts, en temps constant. Ceci nous a mené à un temps d'exécution d'environ 10 minutes sur nos 
machines rien que pour la création de ces transferts à pied, ce qui est, vous en conviendrez, absolument inacceptable.

Afin de remédier à ce problème critique, nous nous sommes penchés sur des structures de données plus adaptées à ce type de problème. Suite à une série de recherches et discussions avec
nos collègues, nous avons opté pour le \emph{BallTree}, une structure de données arborescente où chaque nœud représente une boule dans l'espace N-dimensionnel contenant un sous-ensemble d'arrêts.
Cette structure permet de récupérer efficacement les voisins d'un arrêts donné dans un rayon donné à l'aide de requêtes rapides.

\subsubsection{La classe Walk}
\label{sec:walk}
Classe simple, représentant un transfert à pied entre deux arrêts. Ces objets sont contenus sous forme de liste dans les arrêts correspondants.

\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\
    \hline
    departure & final Stop & L'arrêt de départ du transfert à pied \\
    destination & final Stop & L'arrêt d'arrivée du transfert à pied \\
    duration & final int & La durée en secondes du transfert à pied \\
    \hline
    \end{tabular}
    \caption{Classe Walk}
\end{table}

\newpage
\subsection{Complexité de l'initialisation}
Bien qu'étant une étape antérieure à l'exécution de l'algorithme, il reste important de discuter la complexité de cette étape. En effet, si nous avions choisi d'absolument ignorer
l'aspect de la complexité, nous aurions pu rester sur une implémentation brute-force, prenant 10 minutes à l'exécution. Bien entendu, pour éviter ces absurdités, nous avons apporté
un soin particulier à la création de ces structures de données.

\subsubsection{Complexité temporelle}
L'initialisation des données se fait en plusieurs étapes, chacune ayant sa propre complexité. Premièrement, nous avons la lecture des fichiers CSV, qui a naturellement une complexité
linéaire $O(n)$, où $n$ est le nombre de lignes dans le fichier. 

Ensuite, pour la création des connexions, nous itérons dans tous les trajets et, pour chaque trajet, nous itérons dans leurs heures d'arrêts associés. Notons $n$ le nombre de trajets et $m$ le 
nombre d'arrêts associés à chaque trajet. La complexité de cette étape est donc $O(n \cdot m)$. Une fois la liste de connexions créée, nous procédons au tri de celle-ci en se basant sur 
l'heure de départ de chaque connexion à l'aide de l'algorithme de tri \emph{TimSort}, utilisé par \emph{Collections.sort()}. Ceci se fait dans les pires et
moyen cas avec une complexité de $O(n \log n)$, où $n$ est le nombre de connexions avec un meilleur cas s'exécutant en $O(n)$ (si la liste est déjà majoritairement triée).

Finalement, le plus intéressant, la construction du \emph{BallTree} et des transferts à pied. La construction de notre \emph{BallTree} se fait de manière récursive, en divisant à chaque appel 
récursif l'ensemble des arrêts en deux sous-ensembles. Pour ce faire, des méthodes annexes comme \emph{FindFarthest} ou \emph{ComputeCenter} sont utilisées. Chacune d'entre elles s'exécute en 
temps linéaire, $O(n)$, où $n$ est le nombre d'arrêts dans l'ensemble de données. Quatres fonctions linéaires sont executées à chaque appel récursif, ce qui nous amène à une complexité de 
$4 * O(n)$, ce que l'on peut résumer à $O(n)$. Finalement, concernant les appels récursifs, en supposant le partitionnement parfait, nous avons une profondeur d'arbre de $\log n$ et donc 
$O(n \log n)$ pour la construction de l'arbre complet.

Suite à quelques essais et tests, nous nous sommes rendus compte que le partitionnement n'est pas toujours optimal, cela étant probablement dû à la non-uniformité dans la répartition des arrêts à
travers la Belgique. Ceci nous permet de conclure, pour la complexité de la construction de notre \emph{BallTree}, que nous avons une complexité de $O(n \log n)$ dans le cas moyen ou optimal et de 
$O(n^2)$ dans le pire des cas. Cependant, ce dernier cas est très peu probable dans la pratique. En effet, la construction de l'arbre se fait en 400 millisecondes en moyenne sur nos machines, ce qui 
est tout à fait acceptable contrairement à l'implémentation brute-force envrion 1500 fois plus lente avec un temps d'exécution de 10 minutes.

\begin{algorithm}[H]
    \footnotesize
    \SetAlgoNlRelativeSize{-1}
    \DontPrintSemicolon
    \KwIn{collection \texttt{stops}}
    \KwOut{racine d'un \texttt{BallTree} ou \texttt{null}}
    
    \If{\texttt{stops} est vide}{
      \Return \texttt{null}\;
    }
    \If{$|\texttt{stops}|\le\texttt{leafSize}$}{
      \Return \texttt{LeafNode}(\texttt{stops})\;
    }
    
    \tcp{Trouver deux pivots distants}
    $(p_1,p_2)\gets \Call{FindFarthest}{\texttt{stops}}$\;
    
    \tcp{Partitionner selon la distance aux pivots}
    $\texttt{left}\gets\emptyset$, \quad $\texttt{right}\gets\emptyset$\;
    \ForEach{$s\in\texttt{stops}$}{
      \If{$\dist(p_1,s)<\dist(p_2,s)$}{
        $\texttt{left}\gets \texttt{left}\cup\{s\}$\;
      }
      \Else{
        $\texttt{right}\gets \texttt{right}\cup\{s\}$\;
      }
    }
    
    \tcp{Calcul du centre et du rayon du nœud interne}
    $c\gets \Call{ComputeCenter}{\texttt{stops}}$\;
    $r\gets \Call{ComputeRadius}{\texttt{stops},\,c}$\;
    $node\gets \texttt{InternalNode}(c,r)$\;
    
    \tcp{Appels récursifs}
    $node.\mathit{left}\gets \Call{BuildTree}{\texttt{left}}$\;
    $node.\mathit{right}\gets \Call{BuildTree}{\texttt{right}}$\;
    
    \Return $node$\;
    \caption{BuildTree - Construction récursive d'un BallTree}
  \end{algorithm}
  
Une fois l'arbre construit, nous l'utilisons pour faire des requêtes pour trouver les arrêts à une distance donnée de tous les arrêts. Pour analyser la complexité d'une requête, nous allons considérer
plusieurs scénarios. Premièrement, dans un cas moyen voire optimal, à savoir quand la plupart des noeuds sont prunés (c'est-à-dire que plusieurs sous-arbres ne sont pas visités, améliorant ainsi l'efficacité
de la recherche) grâce à la condition \emph{distToCenter - node.radius > maxDist} et que l'arbre est bien équilibré, la complexité est sous-linéaire en $O(\log n + k)$, où $n$ est le nombre d'arrêts 
et $k$ le nombre d'arrêts trouvés dans la distance donnée. En revanche, comme abordé plus haut, nous nous devons de considérer le cas où l'arbre est déséquilibré et/ou que la plupart de noeuds ne sont 
pas prunés durant la recherche (la plupart des sous-arbres sont visités car le rayon de recherche est grand). Dans ce cas, la complexité de la recherche tend vers la linéarité (parcours de l'arbre au complet)
$O(n + k)$, où $n$ est le nombre d'arrêts et $k$ le nombre d'arrêts trouvés dans la distance donnée. Mais, une fois de plus, difficile d'arriver dans ce cas car la Belgique a une superficie de 30 528 km², une
distance Nord-Sud de 225 km et une distance Ouest-Est de 282 km. Additionnellement, le rayon de recherche que nous utilisons est de 500 m, ce qui est relativement faible par rapport à la taille de la Belgique,
nous donne une vitesse de requête de l'orde des 0,015 millisecondes (ce rayon est bien sûr changeable, mais nous avons considéré un rayon de transfert supposé acceptable pour la majorité de la population).

\begin{algorithm}[H]
    \footnotesize
    \SetAlgoNlRelativeSize{-1}
    \DontPrintSemicolon
    \KwIn{nœud \texttt{node}, requête \texttt{q}, distance max \texttt{maxDist}, collection \texttt{out}}
    \KwOut{ajoute dans \texttt{out} tous les stops à distance $\leq \texttt{maxDist}$ de \texttt{q}}
    
    \If{\texttt{node} = \texttt{null}}{
      \Return\;
    }
    
    \If{\texttt{node} est une feuille}{
      \ForEach{$s \in \texttt{node.stops}$}{
        \If{$\dist(q,s) \le \texttt{maxDist}$}{
          \texttt{out} $\gets$ \texttt{out} $\cup \{s\}$\;
        }
      }
      \Return\;
    }
    
    $\texttt{distToCenter} \gets \dist(q, \texttt{node.center})$\;
    
    \If{$\texttt{distToCenter} - \texttt{node.radius} > \texttt{maxDist}$}{
      \Return\;  \tcp*{prune le sous-arbre}
    }
    
    \tcp{Sinon, on explore les deux sous-arbres}
    \texttt{rangeSearch}(\texttt{node.left}, q, \texttt{maxDist}, \texttt{out})\;
    \texttt{rangeSearch}(\texttt{node.right}, q, \texttt{maxDist}, \texttt{out})\;
\caption{rangeSearch - Recherche en rayon dans un BallTree}
\end{algorithm}

Pour construire les transferts à pied, nous itérons donc sur tous les arrêts et, pour chaque arrêt, on récupère tous ses voisins à grâce au \emph{BallTree} fraîchement construit. Ceci nous donne donc une complexité
linéaire pour la boucle princpale $O(n)$, où $n$ est le nombre d'arrêts. Couplé à ceci, les requêtes de voisins, dans un cas moyen voire optimal sont donc de $O(\log n + k)$, où $n$ est le nombre d'arrêts 
et $k$ le nombre d'arrêts trouvés dans la distance donnée ce qui nous donne une complexité totale pour la construction des transferts à pied de $O(nlog(n + k))$.


\subsubsection{Complexité spatiale}
Chaque donnée des fichiers CSV est chargée en mémoire, impliquant une complexité spatiale de $O(n)$, où $n$ est le nombre de lignes total dans tous les fichiers réunis. Ensuite, les objets
comme les connexions, le \emph{BallTree} et les transferts à pied sont créés mais en utilisant les données initiales par référence. De ce fait, la complexité spatiale de ces objets se résume à leurs
donnée utiles (\emph{overhead}) et à la mémoire utilisée pour les références. En d'autres termes, la complexité spatiale de ces objets est très petite mais tout de même à considérer étant donné leur nombre.

Abordons maintenant un aspect de la complexité spatial qui n'est que `temporaire'. Le tri \emph{TimSort} utilise un espace supplémentaire de $O(n)$ pour le stockage temporaire des données pendant le tri uniquement.
La construction du \emph{BallTree} se faisant récursivement, il faut considérer les appels sur le stack. Ceux-ci dépendent en fonction de la taille des feuilles (le paramète \emph{leafSize}). En effet, celui-ci
détermine le nombre maximal d'arrêts contenus sur une feuille. Plus ce nombre est grand, moins l'arbre sera grand et occupera d'espace en mémoire mais plus les requêtes seront longues. Plus ce nombre est petit,
plus on augmente le nombre d'appels récursifs (risquant ainsi un StackOverflowError qui fait crash le programme) et plus on augmente la taille de l'arbre et donc l'espace en mémoire mais affinant la vitesse de
requêtes (note: une taille de feuille minimale ne signifie pas la vitesse de requête minimale). Voici un graphe pour illustrer ce propos:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{images/feuille-nb-appels-récursifs.png}
    \caption{Nombre d'appels récursifs et temps de construction des transferts à pied en fonction de la taille des feuilles}
    \label{fig:leafsize}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/average-query-time.png}
    \caption{Temps de requête moyen en fonction de la taille des feuilles}
    \label{fig:leafsize}
\end{figure}


\newpage
\section{Le Connexion Scan Algorithm}
\subsection{Choix de l'algorithme}
Dans le cadre de ce projet, nous avons choisi d'implémenter le \emph{Connection Scan Algorithm} (CSA) pour la recherche de chemin.
Cet algorithme est particulièrement adapté pour les réseaux de transport en commun, car il permet de trouver rapidement le meilleur chemin
entre deux arrêts en tenant compte des horaires de départ et d'arrivée. Le CSA a été conçu spécifiquement pour traiter les problèmes de planification d'itinéraires 
dans les systèmes de transport en commun. Cependant, il y avait d'autres algorithmes qui auraient pu être utilisés, tels que \emph{Dijkstra} ou \emph{A*}, 
alors pourquoi avoir fait ce choix.

\subsubsection{Fonctionnement}
\textbf{CSA}: Est basé sur une approche de recherche de chemin qui utilise une liste triée de connexions entre arrêts, et parcourt ces connexions de manière séquentielle.
Il parcourt les connexions dans l'ordre croissant du temps de départ, en mettant à jour les meilleurs temps d'arrivée à chaque arrêt. Il est
spécialisé pour les horaires de transports publics. 


\textbf{Dijkstra}: Cherche le plus court chemin en partant du noeud de départ et en explorant tous les voisins, en choisissant toujours le chemin avec 
le coût total le plus faible.
buildWalks
\textbf{A*}: Est une amélioration de Dijkstra qui utilise une heuristique pour guider la recherche vers la destination. Il est plus efficace que Dijkstra dans certains cas,
mais il nécessite une bonne heuristique pour fonctionner correctement.

\subsubsection{Facilité d'implémentation avec GTFS}
\textbf{CSA}: Est spécifiquement conçu pour fonctionner avec les fichiers GTFS et lit directement les connexions linéairement après le parsing et le tri des horaires.
triées par heure, il n'y a pas besoin de convertir les données en graphe.

\textbf{Dijkstra}: Nécessite de transformer les données de GTFS en graphe temporel (chaque arrêt devient un noeud).
Cette implémentation est moins naturelle que pour CSA mais marche tout aussi bien.

\textbf{A*}: Etant comme Dijkstra mais avec une heuristique, donc il faut lui ajouter l'heuristique. 
Il nécessite aussi une représentation temporelle du graphe.

\subsubsection{Complexité}
\textbf{CSA}: $O(n)$, où $n$ est le nombre de connexions. Très rapide en pratique pour les requêtes "earliest arrival" grâce au tri temporel. 
Cependant, il demande un tri préalablement, ce qui donne une complexité de $O(n \log n)$ pour le tri.

\textbf{Dijkstra}: $O((V + E) \log V)$, où $V$ est le nombre de noeuds et $E$ le nombre d'arêtes.

\textbf{A*}: $O((V + E) \log V)$, mais dépend de la qualité de l'heuristique. Il peut être plus rapide que Dijkstra si l'heuristique est bonne.

\subsubsection{Choix final}
De part la facilité d'implémentation avec les fichiers GTFS, la rapidité de l'algorithme et le fait qu'il soit conçu pour les horaires de transports publics,
nous avons choisi d'implémenter le \emph{Connection Scan Algorithm} (CSA) pour notre projet.

\subsection{Explication et description de l'algorithme}
Le Connection Scan Algorithm (CSA) est une méthode efficace pour résoudre les problèmes de planification d'itinéraires dans 
les réseaux de transports en commun basés sur des horaires, comme les trains et les bus. Contrairement aux algorithmes classiques 
qui utilisent une file de priorité (comme Dijkstra), le CSA se base sur une liste triée de tous les transports en commun, classés par 
leur heure de départ.

Il parcourt cette liste de manière séquentielle pour déterminer rapidement les meilleures connections possibles pour atteindre une 
destination dans un délai optimal ou avec le moins de changements de véhicule.

\subsection{Structures de l'algorithme et implémentation}
l'algorithme est stocké dans une classe \texttt{PathFinder} qui contient la méthode findPath qui implémente l'algorithme CSA.
\begin{table}[h]
  \centering
  \begin{tabular}{|l|l|p{8cm}|}
  \hline
  \textbf{Attribut/Méthode} & \textbf{Type/Retour} & \textbf{Description} \\
  \hline
  stopMap & Map$<$String, Stop$>$ & Map contenant les arrêts, indexés par leur identifiant. \\
  tripMap & Map$<$String, Trip$>$ & Map contenant les trajets, indexés par leur identifiant. \\
  routeMap & Map$<$String, Route$>$ & Map contenant les routes, indexées par leur identifiant. \\
  connexions & List$<$Connexion$>$ & Liste des connexions disponibles. \\
  \hline
  PathFinder & Constructeur & Initialise les maps des arrêts, trajets et routes. \\
  findPath & void & Implémente l'algorithme pour trouver le meilleur chemin dans le graphe. \\
  findStopsByName & List<Stop> & Recherche tous les arrêts du même nom dans la map des arrêts à partir du string donné en paramètre. \\
  \hline
  \end{tabular}
  \caption{Classe PathFinder}
\end{table}

\subsection{Pseudo-code}
\begin{algorithm}[H]
  \footnotesize
  \SetAlgoNlRelativeSize{-1}
  \DontPrintSemicolon
  \KwIn{start, destination, time}
  \KwOut{Affiche le chemin optimal ou un message d'erreur}
  \tcp{La liste de connexions est triée par heure de départ préalablement durant le parsing}
  
  Trouver \texttt{starting\_stops} et \texttt{end\_stops} dans \texttt{stopMap} \;
  \If{données invalides ou start = destination}{
      Afficher une erreur et \Return \;
  }
  
  Initialiser \texttt{shortestPath[stop]} à $\infty$ pour chaque stop \;
  \texttt{Mettre shortestPath[starting\_stop]} $\gets$ temps de départ \;
  
  \texttt{previousConnection} $\gets$ map vide \;
  
  \ForEach{connexion \texttt{c} dans \texttt{connexions}}{
      Récupérer \texttt{depart, arrive, depTime, arrTime} \;
      \If{\texttt{shortestPath[dep]} $\leq$ \texttt{depTime} \textbf{et} \texttt{shortestPath[arrive]} $>$ \texttt{arrTime}}{
          Mettre à jour \texttt{shortestPath[arrive]} et \texttt{previousConnection[arrive]} \;
      }
      \ForEach{walk depuis \texttt{depart}}{
          Calculer \texttt{walkTime} \;
          \If{\texttt{shortestPath[walkArr]} $>$ \texttt{walkTime}}{
              Mettre à jour \texttt{shortestPath[walkArr]} et \texttt{previousConnection[walkArr]} \;
          }
      }
  }

  \texttt{currentStop} $\gets$ \texttt{end\_stop} \;
  \While{\texttt{currentStop} dans \texttt{previousConnection}}{
      Ajouter la connexion à \texttt{path} au début \;
      \texttt{currentStop} $\gets$ origine de la connexion \;
  }
  
  \If{\texttt{currentStop} $\ne$ \texttt{starting\_stop}}{
      Afficher ``No path found'' et \Return \;
  }
  
  \If{\texttt{path} vide}{
      Afficher ``No path found'' \;
  }
  \Else{
      \ForEach{connexion dans \texttt{path}}{
          Afficher les infos de la connexion \;
      }
  }
  \caption{CSA --- Recherche de chemin entre deux arrêts sans marche à pied}
  \end{algorithm}
    
\subsection{Complexité sans la marche à pied}
Le début de l'algorithme se passe dans le parser, où nous lisons les fichiers CSV et construisons les connexions entre arrêts.
C'est alors, qu'en fin de parsing nous allons trier les connexions par heure de départ.
Ce tri a une complexité en $O(n \log n)$, où $n$ est le nombre de connexions. Nous utilisons Collections.sort(allConnexions) qui utilise un 
TimSort qui est un algorithme de tri se basant sur le tri par insertion et le tri fusion.

Vient ensuite la partie principale du CSA, où nous allons parcourir toutes les connexions une par une.
Ceci se fait en $O(n)$, où $n$ est le nombre de connexions. Etant donné que nous avons déjà trié les connexions, il suffit de les parcourir. 
De plus, étant donné que nous parcourons toutes les connexions, nous pouvons même dire que nous sommes en $\Theta(n)$.
Ainsi, la complexité totale de l'algorithme est dominée par le tri initial des connexions, ce qui donne une complexité globale de $O(n \log n)$, où $n$ 
est le nombre de connexions. Cette complexité est particulièrement avantageuse pour les grands ensembles de données, car elle permet un traitement efficace 
des requêtes après le prétraitement initial, cependant celle-ci demande un tri sur l'entièreté des connexions et est donc la partie la plus lourde du processus.

Tout ceci nous amène donc à une complexité totale de $O(n \log n)$ pour le parsing et la recherche de chemin, où $n$ est le nombre de connexions.

\section{Classes utilisées}

\section{Sources-bibliographie}
\cite{dibbelt2017connection} 
\cite{butts2020raptor}
\cite{epfl2024cs108}
\cite{transnetlabCSA}
\cite{gtfsReference}
\cite{futura2009distance}
\cite{geeko2018distance}
\cite{geeksforgeeks_haversine}
\cite{wikipedia_geohash}
\cite{mattaparthi2024ballkd}
\cite{fieldsend_onlineballtree}
\cite{woltmann2025astar}
\cite{wikipedia_astar}
\cite{geeksforgeeks_astar}
\cite{wikipedia_dijkstra}

\printbibliography


\end{document}